{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2965251,"sourceType":"datasetVersion","datasetId":1817999}],"dockerImageVersionId":30357,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nimport os, shutil\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-22T15:07:01.669645Z","iopub.execute_input":"2023-01-22T15:07:01.670139Z","iopub.status.idle":"2023-01-22T15:07:12.211534Z","shell.execute_reply.started":"2023-01-22T15:07:01.670033Z","shell.execute_reply":"2023-01-22T15:07:12.210074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = \"../input/vegetable-image-dataset/Vegetable Images/train\"\nvalidation_path = \"../input/vegetable-image-dataset/Vegetable Images/validation\"\ntest_path = \"../input/vegetable-image-dataset/Vegetable Images/test\"\n\nimage_categories = os.listdir('../input/vegetable-image-dataset/Vegetable Images/train')\n\ndef plot_images(image_categories):\n    \n    plt.figure(figsize=(12, 12))\n    for i, cat in enumerate(image_categories):\n        image_path = train_path + '/' + cat\n        images_in_folder = os.listdir(image_path)\n        first_image_of_folder = images_in_folder[0]\n        first_image_path = image_path + '/' + first_image_of_folder\n        img = image.load_img(first_image_path)\n        img_arr = image.img_to_array(img)/255.0\n    \n        plt.subplot(4, 4, i+1)\n        plt.imshow(img_arr)\n        plt.title(cat)\n        plt.axis('off')\n        \n    plt.show()\n\nplot_images(image_categories)","metadata":{"execution":{"iopub.status.busy":"2023-01-22T15:07:12.214529Z","iopub.execute_input":"2023-01-22T15:07:12.215400Z","iopub.status.idle":"2023-01-22T15:07:18.266486Z","shell.execute_reply.started":"2023-01-22T15:07:12.215356Z","shell.execute_reply":"2023-01-22T15:07:18.265684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = ImageDataGenerator(rescale = 1.0/255.0) # Normalise the data\ntrain_image_generator = train_gen.flow_from_directory(\n                                            train_path,\n                                            target_size=(150, 150),\n                                            batch_size=32,\n                                            class_mode='categorical')\nval_gen = ImageDataGenerator(rescale = 1.0/255.0) # Normalise the data\nval_image_generator = train_gen.flow_from_directory(\n                                            validation_path,\n                                            target_size=(150, 150),\n                                            batch_size=32,\n                                            class_mode='categorical')\n\ntest_gen = ImageDataGenerator(rescale = 1.0/255.0) # Normalise the data\ntest_image_generator = train_gen.flow_from_directory(\n                                            test_path,\n                                            target_size=(150, 150),\n                                            batch_size=32,\n                                            class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-01-22T15:07:18.267571Z","iopub.execute_input":"2023-01-22T15:07:18.267979Z","iopub.status.idle":"2023-01-22T15:07:20.571414Z","shell.execute_reply.started":"2023-01-22T15:07:18.267953Z","shell.execute_reply":"2023-01-22T15:07:20.570061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_map = dict([(v, k) for k, v in train_image_generator.class_indices.items()])\nprint(class_map)","metadata":{"execution":{"iopub.status.busy":"2023-01-22T15:07:20.574291Z","iopub.execute_input":"2023-01-22T15:07:20.575757Z","iopub.status.idle":"2023-01-22T15:07:20.584823Z","shell.execute_reply.started":"2023-01-22T15:07:20.575704Z","shell.execute_reply":"2023-01-22T15:07:20.581161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#yo neeraj this is the actual \"building the model\" part\n\nmodel = Sequential() # model object\n\n# Add Layers\nmodel.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=[150, 150, 3]))\nmodel.add(MaxPooling2D(2, ))\nmodel.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(2))\n\n# Flatten the feature map\nmodel.add(Flatten())\n\n# Add the fully connected layers\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(15, activation='softmax'))\n\n# print the model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-22T15:07:20.586962Z","iopub.execute_input":"2023-01-22T15:07:20.587806Z","iopub.status.idle":"2023-01-22T15:07:20.813184Z","shell.execute_reply.started":"2023-01-22T15:07:20.587767Z","shell.execute_reply":"2023-01-22T15:07:20.811788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(patience=5) # Set up callbacks\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\nhist = model.fit(train_image_generator, \n                 epochs=100, \n                 verbose=1, \n                 validation_data=val_image_generator, \n                 steps_per_epoch = 15000//32, \n                 validation_steps = 3000//32, \n                 callbacks=early_stopping)","metadata":{"execution":{"iopub.status.busy":"2023-01-22T15:07:20.814249Z","iopub.execute_input":"2023-01-22T15:07:20.815507Z","iopub.status.idle":"2023-01-22T15:45:49.994278Z","shell.execute_reply.started":"2023-01-22T15:07:20.815409Z","shell.execute_reply":"2023-01-22T15:45:49.993594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This part shows the accuracy of this model on validation data","metadata":{}},{"cell_type":"code","source":"h = hist.history\nplt.style.use('ggplot')\nplt.figure(figsize=(10, 5))\nplt.plot(h['loss'], c='red', label='Training Loss')\nplt.plot(h['val_loss'], c='red', linestyle='--', label='Validation Loss')\nplt.plot(h['accuracy'], c='blue', label='Training Accuracy')\nplt.plot(h['val_accuracy'], c='blue', linestyle='--', label='Validation Accuracy')\nplt.xlabel(\"Number of Epochs\")\nplt.legend(loc='best')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-01-22T15:45:49.995210Z","iopub.execute_input":"2023-01-22T15:45:49.995461Z","iopub.status.idle":"2023-01-22T15:45:55.942908Z","shell.execute_reply.started":"2023-01-22T15:45:49.995439Z","shell.execute_reply":"2023-01-22T15:45:55.941671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"THe accuracy, about 91%.... it's alright ig.. resnet wouldve been more accurate but yeah......","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_image_generator)","metadata":{"execution":{"iopub.status.busy":"2023-01-22T15:45:55.944464Z","iopub.execute_input":"2023-01-22T15:45:55.944835Z","iopub.status.idle":"2023-01-22T15:46:25.790716Z","shell.execute_reply.started":"2023-01-22T15:45:55.944804Z","shell.execute_reply":"2023-01-22T15:46:25.789343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_predictions(test_image_path, actual_label):\n    test_img = image.load_img(test_image_path, target_size=(150, 150))\n    test_img_arr = image.img_to_array(test_img)/255.0\n    test_img_input = test_img_arr.reshape((1, test_img_arr.shape[0], test_img_arr.shape[1], test_img_arr.shape[2]))\n\n\n    predicted_label = np.argmax(model.predict(test_img_input))\n    predicted_vegetable = class_map[predicted_label]\n    plt.figure(figsize=(4, 4))\n    plt.imshow(test_img_arr)\n    plt.title(\"Predicted Label: {}, Actual Label: {}\".format(predicted_vegetable, actual_label))\n    plt.grid()\n    plt.axis('off')\n    plt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-22T15:46:25.792086Z","iopub.execute_input":"2023-01-22T15:46:25.792487Z","iopub.status.idle":"2023-01-22T15:46:25.801265Z","shell.execute_reply.started":"2023-01-22T15:46:25.792453Z","shell.execute_reply":"2023-01-22T15:46:25.799360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below... im using a icture from the test part f the data set to test it out............. use any image you want to check it out","metadata":{}},{"cell_type":"code","source":"test_image_path = '../input/vegetable-image-dataset/Vegetable Images/test/Broccoli/1011.jpg'\ngenerate_predictions(test_image_path, actual_label='Brocoli')","metadata":{"execution":{"iopub.status.busy":"2023-01-22T15:53:20.971720Z","iopub.execute_input":"2023-01-22T15:53:20.972070Z","iopub.status.idle":"2023-01-22T15:53:21.213275Z","shell.execute_reply.started":"2023-01-22T15:53:20.972045Z","shell.execute_reply":"2023-01-22T15:53:21.212163Z"},"trusted":true},"execution_count":null,"outputs":[]}]}